{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_recommendation_system.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-HtGanjAU42",
        "colab_type": "code",
        "outputId": "ad3a1833-e719-4eab-f7a8-7e021a4badf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIVGURL5AZHl",
        "colab_type": "code",
        "outputId": "ed50a617-ff44-4199-c3b7-9ab4f38b293a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "% pip install pyspark \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
            "\u001b[K     |████████████████████████████████| 215.6MB 99kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKIQg7di97Z-",
        "colab_type": "text"
      },
      "source": [
        "Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxli3hccAtNV",
        "colab_type": "code",
        "outputId": "2aba1605-da8b-43b7-f4a7-6bde4ea23c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
        "from time import time\n",
        "\n",
        "import math\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os       #importing os to set environment variable\n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  !java -version       #check java version\n",
        "install_java()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.2\" 2019-01-15\n",
            "OpenJDK Runtime Environment (build 11.0.2+9-Ubuntu-3ubuntu118.04.3)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.2+9-Ubuntu-3ubuntu118.04.3, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dupCS1_37Ht9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Getting and processing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqt0kDwu7l-b",
        "colab_type": "text"
      },
      "source": [
        "File download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asn7LAINBKWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
        "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3Sm84T7san",
        "colab_type": "text"
      },
      "source": [
        "We also need to define download locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQZiNYbeBM5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets_path = os.path.join('/content/gdrive', 'My Drive')\n",
        "\n",
        "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
        "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ITtPYpu7yBi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now we can proceed with both downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xz3HeIsBP35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
        "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLaWCZbD73hb",
        "colab_type": "text"
      },
      "source": [
        "Both of them are zip files containing a folder with ratings, movies, etc. We need to extract them into its individual folders so we can use each file later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0y7QhjfBUwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)\n",
        "\n",
        "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pye-Fr7F79tq",
        "colab_type": "text"
      },
      "source": [
        "Loading and parsing datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-DCY9tpBZkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = SparkContext('local')\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5STJZFx8EfA",
        "colab_type": "text"
      },
      "source": [
        "So let's load the raw ratings data. We need to filter out the header, included in each file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_MHrx3CBun5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
        "\n",
        "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
        "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPI8CQTJ8F9A",
        "colab_type": "text"
      },
      "source": [
        "Now we can parse the raw data into a new RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2T6HMCBByV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM2hpHny8JYg",
        "colab_type": "text"
      },
      "source": [
        "For illustrative purposes, we can take the first few lines of our RDD to see the result. In the final script we don't call any Spark action (e.g. take) until needed, since they trigger actual computations in the cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MEWXmLcB1Qn",
        "colab_type": "code",
        "outputId": "c4a36c8e-9277-4002-ca93-e26d022c4a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "small_ratings_data.take(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuc96Tia8PZt",
        "colab_type": "text"
      },
      "source": [
        "We proceed in a similar way with the movies.csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMfF3GU8B3mQ",
        "colab_type": "code",
        "outputId": "bddd4831-29f0-47c2-88f3-06997bd40a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
        "\n",
        "small_movies_raw_data = sc.textFile(small_movies_file)\n",
        "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
        "\n",
        "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
        "    \n",
        "small_movies_data.take(3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Toy Story (1995)'),\n",
              " ('2', 'Jumanji (1995)'),\n",
              " ('3', 'Grumpier Old Men (1995)')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u52rnWHr8W-l",
        "colab_type": "text"
      },
      "source": [
        "Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWa2YIISB586",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=None)\n",
        "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyuBgiHB8YpZ",
        "colab_type": "text"
      },
      "source": [
        "Selecting ALS parameters using the small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lds8xUAGB8Xl",
        "colab_type": "code",
        "outputId": "50b7d504-62a5-4ffc-e967-0111fb974662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "\n",
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "seed = 250\n",
        "iterations = 10\n",
        "regularization_parameter = 0.1\n",
        "ranks = [4, 8, 12]\n",
        "errors = [0, 0, 0]\n",
        "err = 0\n",
        "tolerance = 0.02\n",
        "\n",
        "min_error = float('inf')\n",
        "best_rank = -1\n",
        "best_iteration = -1\n",
        "for rank in ranks:\n",
        "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
        "                      lambda_=regularization_parameter)\n",
        "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    errors[err] = error\n",
        "    err += 1\n",
        "    print('For rank %s the RMSE is %s' % (rank, error))\n",
        "    if error < min_error:\n",
        "        min_error = error\n",
        "        best_rank = rank\n",
        "\n",
        "print('The best model was trained with rank %s' % best_rank)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For rank 4 the RMSE is 0.9219502380669411\n",
            "For rank 8 the RMSE is 0.9240152640633886\n",
            "For rank 12 the RMSE is 0.9223173115607685\n",
            "The best model was trained with rank 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39wX3R6A8lTh",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at how our predictions look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1ctjTvB_Fl",
        "colab_type": "code",
        "outputId": "5456dc51-3c81-4570-fd39-661e8d2e441f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "predictions.take(3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((232, 37739), 3.4503724590109863),\n",
              " ((298, 69069), 2.248725228962298),\n",
              " ((249, 69069), 4.038156902413192)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTPw0cLr8pWh",
        "colab_type": "text"
      },
      "source": [
        "Basically we have the UserID, the MovieID, and the Rating, as we have in our ratings dataset. In this case the predictions third element, the rating for that movie and user, is the predicted by our ALS model.\n",
        "\n",
        "Then we join these with our validation data (the one that includes ratings) and the result looks as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bs9kQEuOgzw",
        "colab_type": "code",
        "outputId": "63555a2a-550a-4a54-de0f-f8a5f09e54b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "rates_and_preds.take(3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 47), (5.0, 4.512483741043782)),\n",
              " ((1, 151), (5.0, 2.9969097532923636)),\n",
              " ((1, 333), (5.0, 4.6120349374165945))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlq1B9an8uWZ",
        "colab_type": "text"
      },
      "source": [
        "To that, we apply a squared difference and the we use the mean() action to get the MSE and apply sqrt.\n",
        "\n",
        "Finally we test the selected model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUzFekrOi_e",
        "colab_type": "code",
        "outputId": "98e2af21-6738-450d-eddb-50fbb7031895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
        "                      lambda_=regularization_parameter)\n",
        "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print ('For testing data the RMSE is %s' % (error))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For testing data the RMSE is 0.9084850145452672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01y7Hw278xq0",
        "colab_type": "text"
      },
      "source": [
        "Using the complete dataset to build the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnasiOPOOkvb",
        "colab_type": "code",
        "outputId": "a027621b-0f4c-4aed-9d7d-6ac188790f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the complete dataset file\n",
        "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
        "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
        "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
        "\n",
        "# Parse\n",
        "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
        "    \n",
        "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 27753444 recommendations in the complete dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-W77V4Z81GN",
        "colab_type": "text"
      },
      "source": [
        "Now we are ready to train the recommender model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30LsjE20OwUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=42)\n",
        "\n",
        "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
        "                           iterations=iterations, lambda_=regularization_parameter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY7QG0X884t8",
        "colab_type": "text"
      },
      "source": [
        "Now we test on our testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiyw_WWEPXzQ",
        "colab_type": "code",
        "outputId": "8df8cde7-c274-49d5-c9b7-09d8215c840d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
        "\n",
        "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print ('For testing data the RMSE is %s' % (error))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For testing data the RMSE is 0.8302558863048242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3qJm2X88Jl",
        "colab_type": "text"
      },
      "source": [
        "How to make recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cejnbYDU9GjN",
        "colab_type": "text"
      },
      "source": [
        "Let's first load the movies complete file for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "medl9ayfPehh",
        "colab_type": "code",
        "outputId": "49c7b777-cbfe-47cc-c311-a0dba9480908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
        "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
        "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
        "\n",
        "# Parse\n",
        "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
        "\n",
        "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
        "    \n",
        "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 58098 movies in the complete dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y0YCeW89KFj",
        "colab_type": "text"
      },
      "source": [
        "Another thing we want to do, is give recommendations of movies with a certain minimum number of ratings. For that, we need to count the number of ratings per movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHAzxWwePhqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_counts_and_averages(ID_and_ratings_tuple):\n",
        "    nratings = len(ID_and_ratings_tuple[1])\n",
        "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
        "\n",
        "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
        "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
        "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTFO7Na39NjH",
        "colab_type": "text"
      },
      "source": [
        "Now we need to rate some movies for the new user. We will put them in a new RDD and we will use the user ID 0, that is not assigned in the MovieLens dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYSQnVrZPkZ9",
        "colab_type": "code",
        "outputId": "59dbafed-dabb-47f7-a70b-f9daa8980cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "new_user_ID = 0\n",
        "\n",
        "# The format of each line is (userID, movieID, rating)\n",
        "new_user_ratings = [\n",
        "     (0,260,9), # Star Wars (1977)\n",
        "     (0,1,8), # Toy Story (1995)\n",
        "     (0,16,7), # Casino (1995)\n",
        "     (0,25,8), # Leaving Las Vegas (1995)\n",
        "     (0,32,9), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
        "     (0,335,4), # Flintstones, The (1994)\n",
        "     (0,379,3), # Timecop (1994)\n",
        "     (0,296,7), # Pulp Fiction (1994)\n",
        "     (0,858,10) , # Godfather, The (1972)\n",
        "     (0,50,8) # Usual Suspects, The (1995)\n",
        "    ]\n",
        "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
        "print ('New user ratings: %s' % new_user_ratings_RDD.take(10))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgauuxzw9Sk9",
        "colab_type": "text"
      },
      "source": [
        "Now we add them to the data we will use to train our recommender model. We use Spark's union() transformation for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykK1-dEMPniI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ574FLJ9V5_",
        "colab_type": "text"
      },
      "source": [
        "And finally we train the ALS model using all the parameters we selected before (when using the small dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97qPpGGpPrCP",
        "colab_type": "code",
        "outputId": "6c8d38f3-4855-4443-9cec-54962f6aaad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t0 = time()\n",
        "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
        "                              iterations=iterations, lambda_=regularization_parameter)\n",
        "tt = time() - t0\n",
        "\n",
        "print (\"New model trained in %s seconds\" % round(tt,3))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New model trained in 250.434 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL7gSOrp9Y2y",
        "colab_type": "text"
      },
      "source": [
        "Getting top recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi69zs-wPt2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
        "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
        "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
        "\n",
        "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
        "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2LhCsv9e9X",
        "colab_type": "text"
      },
      "source": [
        "We have our recommendations ready. Now we can print out the 25 movies with the highest predicted ratings. And join them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum number of counts. First we will do the join and see what does the result looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKxtZkM7PxVn",
        "colab_type": "code",
        "outputId": "fb97066a-8f1e-4483-c5ff-0fbce1992566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
        "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
        "new_user_recommendations_rating_title_and_count_RDD.take(3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7020, ((7.369051204321095, 'Proof (1991)'), 377)),\n",
              " (53352, ((4.640950465134326, 'Sheitan (2006)'), 59)),\n",
              " (162396, ((3.6149795048537037, 'Skiptrace (2016)'), 71))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU49f5NL9ggH",
        "colab_type": "text"
      },
      "source": [
        "So we need to flat this down a bit in order to have (Title, Rating, Ratings Count)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7jGhnsPzh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v5TUU1D9lZo",
        "colab_type": "text"
      },
      "source": [
        "Finally, get the highest rated recommendations for the new user, filtering out movies with less than 25 ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBnfBSUaP2bG",
        "colab_type": "code",
        "outputId": "a24ed478-ad67-4511-edfb-f9f53f47c19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
        "\n",
        "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
        "        '\\n'.join(map(str, top_movies)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOP recommended movies (with more than 25 reviews):\n",
            "('Planet Earth II (2016)', 8.782162460975016, 853)\n",
            "('Planet Earth (2006)', 8.774526563502071, 1384)\n",
            "('Death on the Staircase (Soupçons) (2004)', 8.761032559069003, 130)\n",
            "('Cranford (2007)', 8.740857746924949, 35)\n",
            "('Queen: Days of Our Lives (2011)', 8.73368010857624, 32)\n",
            "(\"Smiley's People (1982)\", 8.727818051629674, 116)\n",
            "(\"Won't You Be My Neighbor? (2018)\", 8.71279032211772, 83)\n",
            "('Alone in the Wilderness (2004)', 8.710514407914904, 343)\n",
            "('Hamlet (Gamlet) (1964)', 8.693348680243808, 37)\n",
            "('Frozen Planet (2011)', 8.691068010499269, 402)\n",
            "('Life (2009)', 8.678069760530349, 166)\n",
            "('Slaying the Badger', 8.668714311244093, 25)\n",
            "('Olive Kitteridge (2014)', 8.66083989330083, 211)\n",
            "('\"Lonely Wife', 8.64651054113206, 43)\n",
            "('\"Crucified Lovers', 8.640151184491975, 25)\n",
            "('The Blue Planet (2001)', 8.63785513016718, 421)\n",
            "('The Farthest (2017)', 8.622016494599773, 28)\n",
            "('\"Civil War', 8.6217137802526, 431)\n",
            "('Strangers in Good Company (1990)', 8.608525001964761, 26)\n",
            "('Blue Planet II (2017)', 8.592068990558925, 349)\n",
            "('Chasing Coral (2017)', 8.581998893379735, 32)\n",
            "('\"Godfather', 8.575313079830405, 60904)\n",
            "('The Godfather Trilogy: 1972-1990 (1992)', 8.573168143373454, 421)\n",
            "('Band of Brothers (2001)', 8.567405070437214, 984)\n",
            "('\"Best of Youth', 8.558087644158558, 548)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6knYOB79pOt",
        "colab_type": "text"
      },
      "source": [
        "Getting individual ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4-2il9YP41C",
        "colab_type": "code",
        "outputId": "43f0c277-263f-4678-dea2-dbfd9c376d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
        "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
        "individual_movie_rating_RDD.take(1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Rating(user=0, product=116688, rating=2.108191486766258)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adoxz7X79s73",
        "colab_type": "text"
      },
      "source": [
        "Persisting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_SG1GdQY8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = os.path.join('..', 'models', 'movie_lens_als')\n",
        "\n",
        "# Save and load model\n",
        "model.save(sc, model_path)\n",
        "same_model = MatrixFactorizationModel.load(sc, model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NDQ1kx9w9Q",
        "colab_type": "text"
      },
      "source": [
        "Genre and other fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewfR9zMZ9z6y",
        "colab_type": "text"
      },
      "source": [
        "We havent used the genre and timestamp fields in order to simplify the transformations and the whole tutorial. Incorporating them doesn't reprensent any problem. A good use could be filtering recommendations by any of them (e.g. recommendations by genre, or recent recommendations) like we have done with the minimum number of ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YeYsCcL61K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}